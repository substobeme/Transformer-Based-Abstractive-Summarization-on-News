{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e763879b-e457-4d56-8e90-c2409dbb2e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0997e4c5-5f58-443f-ab4d-b75d741314ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"nlplabtdtu/xlsum_en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a529b69c-544f-46d4-b320-b276633c448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(dataset):\n",
    "    for split in ['train', 'validation', 'test']:\n",
    "        for example in dataset[split]:\n",
    "            yield example['text'] + ' ' + example['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa1e9b9-b656-4978-b586-43019ced2027",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(get_corpus(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7f272c9-c1a7-4a91-b040-88a10988448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a526a2cf-7e23-478a-ade6-a37463f95cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.train_from_iterator(\n",
    "    corpus,                     \n",
    "    min_frequency=2,       \n",
    "    special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a5adf4c-095c-43fb-b4df-a7dc5b8a094b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1ac7913-79f2-4086-b57c-a1eeb043a50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_tokenizer/vocab.json', 'my_tokenizer/merges.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"my_tokenizer\"\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)  # Create directory if it doesn't exist\n",
    "tokenizer.save_model(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04800458-1c65-4c99-847f-d22c888cc049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizerFast\n",
    "\n",
    "tokenizer = BartTokenizerFast(\n",
    "    vocab_file=f\"{output_dir}/vocab.json\",\n",
    "    merges_file=f\"{output_dir}/merges.txt\",\n",
    "    bos_token=\"<s>\",\n",
    "    eos_token=\"</s>\",\n",
    "    unk_token=\"<unk>\",\n",
    "    pad_token=\"<pad>\",\n",
    "    mask_token=\"<mask>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44307023-ae84-4d93-b347-a94610c5ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from transformers import BartTokenizer, get_linear_schedule_with_warmup\n",
    "from rouge_score import rouge_scorer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ee0b430-44d2-4a40-94d4-f55cd3c63819",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_src_len   = 512      \n",
    "max_tgt_len   = 128      \n",
    "batch_size    = 8\n",
    "epochs        = 10\n",
    "lr            = 0.0001\n",
    "weight_decay  = 0.01\n",
    "grad_clip     = 1.0\n",
    "beam_size     = 4\n",
    "warmup_ratio  = 0.1\n",
    "checkpoint_dir = \"checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a8340dd-ef86-4f15-9d02-221194feee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8c32169-55e3-46d7-8be2-609f48a1d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    src = tokenizer(batch['text'], max_length=max_src_len, truncation=True, padding='max_length')\n",
    "    tgt = tokenizer(batch['target'], max_length=max_tgt_len, truncation=True, padding='max_length')\n",
    "    \n",
    "    return {'input_ids': src.input_ids, 'attention_mask': src.attention_mask, 'labels': tgt.input_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd240c54-5bb7-43f2-9032-6a4281ce5461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(dataset_path):\n",
    "    splits = load_dataset(dataset_path, split={\"train\":\"train\",\"validation\":\"validation\"})\n",
    "    tokenized = splits.map(tokenize, batched=True)\n",
    "    tokenized.set_format(type='torch', columns=['input_ids','attention_mask','labels'])\n",
    "    train_loader = DataLoader(tokenized['train'], batch_size=batch_size, shuffle=True, num_workers=6, pin_memory=True,persistent_workers=True)\n",
    "    valid_loader = DataLoader(tokenized['validation'], batch_size=batch_size, num_workers=5, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "373eef3b-f5ae-4eae-883e-8032338fc88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = get_loaders(\"nlplabtdtu/xlsum_en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a19a977-72c1-481b-8df3-ef87dbb5bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c46b4550-e944-488c-a836-a032c5ae576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainablePositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=1000):\n",
    "        super().__init__()\n",
    "        self.pos = nn.Parameter(torch.zeros(max_len, d_model))\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(0)\n",
    "        return x + self.pos[:seq_len].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38ae0169-068f-450d-ba97-d21f454dfa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerSummarizer(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, d_model=512, nhead=8, enc_layers=3, dec_layers=3, dim_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed       = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_enc     = TrainablePositionalEncoding(d_model)\n",
    "        self.pos_dec     = TrainablePositionalEncoding(d_model)\n",
    "        self.transformer = nn.Transformer(d_model, nhead, enc_layers, dec_layers, dim_ff, dropout, activation='gelu', batch_first=True)\n",
    "        self.out_proj    = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "    def forward(self, src, tgt, src_attention_mask=None, tgt_attention_mask=None):\n",
    "\n",
    "        pad_id = tokenizer.pad_token_id\n",
    "        src_kpm = (src == pad_id)\n",
    "        tgt_kpm = (tgt == pad_id)\n",
    "        \n",
    "        src_emb = self.pos_enc(self.embed(src) * math.sqrt(self.embed.embedding_dim))\n",
    "        tgt_emb = self.pos_dec(self.embed(tgt) * math.sqrt(self.embed.embedding_dim))\n",
    "        \n",
    "        size = tgt.size(1)\n",
    "        tgt_mask = torch.triu(torch.full((size, size), True,dtype=torch.bool), 1).to(device)\n",
    "        \n",
    "        out = self.transformer(src_emb, tgt_emb, tgt_mask=tgt_mask,\n",
    "                               src_key_padding_mask=src_kpm,\n",
    "                               tgt_key_padding_mask=tgt_kpm,\n",
    "                               memory_key_padding_mask=src_kpm\n",
    "                              )\n",
    "        \n",
    "        return self.out_proj(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af4d070a-957a-49d1-9e20-9a9dd2e761c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94f6087e-4e56-49d1-94d3-89c0f3659e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerSummarizer(vocab_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73d3e32a-e458-494f-94e7-4c32109bd5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerSummarizer(\n",
       "  (embed): Embedding(30000, 512)\n",
       "  (pos_enc): TrainablePositionalEncoding()\n",
       "  (pos_dec): TrainablePositionalEncoding()\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (out_proj): Linear(in_features=512, out_features=30000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c44f238d-00be-4d45-afbc-74cd6605c0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecadd79f-a1c6-49d9-82f6-29aaef077019",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6c0a05b-d38a-41e0-a4d2-3ae2efcf1dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = len(train_loader) * epochs\n",
    "warmup_steps = int(total_steps * warmup_ratio)\n",
    "    \n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=warmup_steps,\n",
    "                                            num_training_steps=total_steps\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d801477-aff0-47fb-ae86-3c5ecc598cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: 1\n",
      "GPU 0: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "print(f\"Available GPUs: {torch.cuda.device_count()}\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "723c5059-30ea-4f84-8313-fd5d22251cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, criterion, scheduler, device, vocab_size, pad_token_id, grad_clip=1.0):\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        \n",
    "        src = batch['input_ids'].to(device, non_blocking=True)\n",
    "        src_attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "        tgt = batch['labels'].to(device, non_blocking=True)\n",
    "        \n",
    "        tgt_inp, tgt_lbl = tgt[:, :-1], tgt[:, 1:]\n",
    "        \n",
    "        tgt_attention_mask = (tgt_inp != pad_token_id).to(device, non_blocking=True)\n",
    "        \n",
    "        loss_mask = (tgt_lbl != pad_token_id).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(\n",
    "            src=src,\n",
    "            tgt=tgt_inp,\n",
    "            src_attention_mask=src_attention_mask,\n",
    "            tgt_attention_mask=tgt_attention_mask\n",
    "        )\n",
    "        \n",
    "        loss = criterion(logits.reshape(-1, vocab_size), tgt_lbl.reshape(-1))\n",
    "        \n",
    "        masked_loss = (loss * loss_mask.reshape(-1)).sum() / max(loss_mask.sum(), 1)\n",
    "        \n",
    "        masked_loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        current_loss = masked_loss.item()\n",
    "        total_loss += current_loss\n",
    "        progress_bar.set_postfix({\"loss\": f\"{current_loss:.4f}\"})\n",
    "        \n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "898c4d17-16fb-4de2-88de-132ddbb08cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, criterion, device, vocab_size, pad_token_id, tokenizer):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "    \n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    progress_bar = tqdm(val_loader, desc=\"Validating\")\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for batch in progress_bar:\n",
    "            src = batch['input_ids'].to(device, non_blocking=True)\n",
    "            src_attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "            tgt = batch['labels'].to(device, non_blocking=True)\n",
    "            tgt_inp, tgt_lbl = tgt[:, :-1], tgt[:, 1:]\n",
    "            \n",
    "            tgt_attention_mask = (tgt_inp != pad_token_id).to(device, non_blocking=True)\n",
    "            \n",
    "            loss_mask = (tgt_lbl != pad_token_id).float()\n",
    "            \n",
    "            logits = model(\n",
    "                src=src,\n",
    "                tgt=tgt_inp,\n",
    "                src_attention_mask=src_attention_mask,\n",
    "                tgt_attention_mask=tgt_attention_mask\n",
    "            )\n",
    "            \n",
    "            loss = criterion(logits.reshape(-1, vocab_size), tgt_lbl.reshape(-1))\n",
    "            masked_loss = (loss * loss_mask.reshape(-1)).sum() / max(loss_mask.sum(), 1)\n",
    "            total_loss += masked_loss.item()\n",
    "            \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e6d06a0-e34b-4ba7-81b2-31f695bebaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, train_loader, val_loader, vocab_size, tokenizer, optimizer, criterion, scheduler, pad_token_id, grad_clip):\n",
    "    \n",
    "    model = model.to(device, non_blocking=True)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        train_loss = train_epoch(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            scheduler=scheduler,\n",
    "            device=device,\n",
    "            vocab_size=vocab_size,\n",
    "            pad_token_id=pad_token_id,\n",
    "            grad_clip=grad_clip\n",
    "        )\n",
    "        \n",
    "        val_loss = evaluate(\n",
    "            model=model,\n",
    "            val_loader=val_loader,\n",
    "            criterion=criterion,\n",
    "            device=device,\n",
    "            vocab_size=vocab_size,\n",
    "            pad_token_id=pad_token_id,\n",
    "            tokenizer=tokenizer\n",
    "        )\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'train_loss': train_loss,\n",
    "                    'val_loss': val_loss\n",
    "                    }, f\"{checkpoint_dir}/transformer_epoch_{epoch+1}.pt\")\n",
    "        print(f\"Saved checkpoint for epoch {epoch+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cd8ea6f-c817-46d9-8b35-0a6dc191334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"The PyTorch API of nested tensors is in prototype stage\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*The current process just got forked.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8f51030-7b8f-47b5-af0e-0cbb9bcf95f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db30f300-446c-4b6a-98e9-e26d1bb4b0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 38316/38316 [41:12<00:00, 15.49it/s, loss=3.9932]\n",
      "Validating: 100%|██████████| 1442/1442 [00:49<00:00, 29.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.6396 | Val Loss: 4.3961\n",
      "Saved checkpoint for epoch 1\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 38316/38316 [41:11<00:00, 15.51it/s, loss=5.9295]\n",
      "Validating: 100%|██████████| 1442/1442 [00:50<00:00, 28.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.1076 | Val Loss: 3.7102\n",
      "Saved checkpoint for epoch 2\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 38316/38316 [41:08<00:00, 15.52it/s, loss=3.3837]\n",
      "Validating: 100%|██████████| 1442/1442 [00:49<00:00, 29.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.6406 | Val Loss: 3.4667\n",
      "Saved checkpoint for epoch 3\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 38316/38316 [41:11<00:00, 15.50it/s, loss=3.7923]\n",
      "Validating: 100%|██████████| 1442/1442 [00:49<00:00, 29.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.3926 | Val Loss: 3.3279\n",
      "Saved checkpoint for epoch 4\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 38316/38316 [41:19<00:00, 15.46it/s, loss=3.6574] \n",
      "Validating: 100%|██████████| 1442/1442 [00:49<00:00, 29.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.2176 | Val Loss: 3.2373\n",
      "Saved checkpoint for epoch 5\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 38316/38316 [41:09<00:00, 15.51it/s, loss=2.1435]\n",
      "Validating: 100%|██████████| 1442/1442 [00:50<00:00, 28.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.0772 | Val Loss: 3.1787\n",
      "Saved checkpoint for epoch 6\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 38316/38316 [41:13<00:00, 15.49it/s, loss=3.6840]\n",
      "Validating: 100%|██████████| 1442/1442 [00:49<00:00, 28.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.9566 | Val Loss: 3.1343\n",
      "Saved checkpoint for epoch 7\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 38316/38316 [41:13<00:00, 15.49it/s, loss=2.8114]\n",
      "Validating: 100%|██████████| 1442/1442 [00:49<00:00, 29.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.8510 | Val Loss: 3.1043\n",
      "Saved checkpoint for epoch 8\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 38316/38316 [41:14<00:00, 15.49it/s, loss=4.8861]\n",
      "Validating: 100%|██████████| 1442/1442 [00:49<00:00, 29.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.7561 | Val Loss: 3.0839\n",
      "Saved checkpoint for epoch 9\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 38316/38316 [41:10<00:00, 15.51it/s, loss=4.2148]\n",
      "Validating: 100%|██████████| 1442/1442 [00:49<00:00, 29.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.6749 | Val Loss: 3.0764\n",
      "Saved checkpoint for epoch 10\n"
     ]
    }
   ],
   "source": [
    "train(model, epochs, train_loader, valid_loader, vocab_size, tokenizer, optimizer, criterion, scheduler, pad_token_id, grad_clip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
